{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helloworld.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xKKXKnD83Gax"
      ],
      "mount_file_id": "1huyyujOy5zFxAnd6erWedN9a92zggTxH",
      "authorship_tag": "ABX9TyNZdPaIRnaR8EKEvRwpqehW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juntaozhang/ML/blob/main/helloworld.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meI4H1SfM1Xr"
      },
      "source": [
        "# pytorch example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGo1cdlzMwTG"
      },
      "source": [
        "https://github.com/ShusenTang/Dive-into-DL-PyTorch\n",
        "\n",
        "https://github.com/ShusenTang/Dive-into-DL-PyTorch/blob/master/docs/chapter02_prerequisite/2.2_tensor.md\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js3HEj7Na0Kx"
      },
      "source": [
        "# x = torch.empty(5, 3)\n",
        "# print(x)\n",
        "\n",
        "# x = torch.rand(5, 3)\n",
        "# print(x)\n",
        "\n",
        "# x = torch.zeros(5, 3, dtype=torch.long)\n",
        "# print(x)\n",
        "\n",
        "# x = torch.tensor([[5.5, 3],[1.5, 1]])\n",
        "# print(x)\n",
        "# print(x.size())\n",
        "# print(x.shape)\n",
        "\n",
        "x = torch.ones(3, 3)\n",
        "y = torch.eye(3)*2\n",
        "# print(x + y)\n",
        "# print(torch.add(x, y))\n",
        "# result = torch.empty(3, 3)\n",
        "# torch.add(x, y, out=result)\n",
        "# print(result)\n",
        "# y.add_(x)\n",
        "# print(y)\n",
        "# print(y[:,1])\n",
        "\n",
        "# x = torch.ones(2, 2, requires_grad=True)\n",
        "# print(x)\n",
        "# print(x.grad_fn)\n",
        "\n",
        "# print(x)\n",
        "# print(y)\n",
        "# print(x.mul(y))\n",
        "\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "import torch, torchvision\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "labels = torch.rand(1, 1000)\n",
        "prediction = model(data) # forward pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoQXeUC4pEiG"
      },
      "source": [
        "loss = (prediction - labels).sum()\n",
        "print(loss)\n",
        "loss.backward() # backward pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yte1T376VEz0"
      },
      "source": [
        "https://pytorch.apachecn.org/docs/1.7/05.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi1QkMwIEnJw"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "external_grad = torch.tensor([0.2, 0.8])\n",
        "Q = 3*a**3 - b**2\n",
        "\n",
        "print(Q)\n",
        "print((9*a**2) * external_grad)\n",
        "print(-2*b * external_grad)\n",
        "\n",
        "Q.backward(gradient=external_grad)\n",
        "print(a.grad.data)\n",
        "print(b.grad)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKKXKnD83Gax"
      },
      "source": [
        "# OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omKI9FEo3Oo4"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "img = cv.imread('home.jpg')\n",
        "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "sift = cv.xfeatures2d.SIFT_create()\n",
        "kp = sift.detect(gray,None)\n",
        "img=cv.drawKeypoints(gray,kp,img)\n",
        "cv.imwrite('sift_keypoints.jpg',img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwfDq-SvM32B"
      },
      "source": [
        "# Cifar10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B__SdjvxlxLr",
        "outputId": "9fd354e5-ae29-4871-ca5d-f888a540b273"
      },
      "source": [
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "print(torch.cuda.is_available())\n",
        "%cd /content/drive/MyDrive/ML/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "True\n",
            "/content/drive/MyDrive/ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYITH7-x_zQY"
      },
      "source": [
        "%mkdir  cifar10/test2_momentum/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "MaP0Kuox4edH",
        "outputId": "09684c49-1162-43c7-bbeb-af967c9cd3db"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "# import gc\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "# gc.collect()\n",
        "\n",
        "print(device)\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "            (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
        "    )\n",
        "])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "n_total_step = len(train_loader)\n",
        "print(n_total_step)\n",
        "\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "input_lastLayer = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(input_lastLayer, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        labels_hat = model(imgs)\n",
        "        n_corrects = (labels_hat.argmax(axis=1) == labels).sum().item()\n",
        "        loss_value = criterion(labels_hat, labels)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        print(f\"epoch {epoch + 1}/{num_epochs}, step: {i + 1}/{n_total_step}: loss = {loss_value:.5f}, acc = {100 * (n_corrects / labels.size(0)):.2f}%\")\n",
        "\n",
        "    torch.save(model, './cifar10/test_vgg16_cifar10_{}.pth'.format(i))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        number_corrects = 0\n",
        "        number_samples = 0\n",
        "        for i, (test_images_set, test_labels_set) in enumerate(test_loader):\n",
        "            test_images_set = test_images_set.to(device)\n",
        "            test_labels_set = test_labels_set.to(device)\n",
        "\n",
        "            y_predicted = model(test_images_set)\n",
        "            labels_predicted = y_predicted.argmax(axis=1)\n",
        "            number_corrects += (labels_predicted == test_labels_set).sum().item()\n",
        "            number_samples += test_labels_set.size(0)\n",
        "        print(f\"Overall accuracy {(number_corrects / number_samples) * 100}%\")\n",
        "\n",
        "heatmap = pd.DataFrame(data=0, index=classes, columns=classes)\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(batch_size):\n",
        "            true_label = labels[i].item()\n",
        "            predicted_label = predicted[i].item()\n",
        "            heatmap.iloc[true_label, predicted_label] += 1\n",
        "_, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(heatmap, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b52de0ab4965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# import gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabbreviated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# gc.collect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mmemory_summary\u001b[0;34m(device, abbreviated)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_key\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubmetric_key\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"current\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0mpeak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"peak\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mallocated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"allocated\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'allocated_bytes.all.current'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rME0Jcc_rEpI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "8057377c-3dc7-427b-97ea-f22610952ac5"
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "base_path = \"test3\"\n",
        "tensorboard_name = base_path\n",
        "# 轮次\n",
        "epoch = 50\n",
        "\n",
        "labels = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
        "\n",
        "\n",
        "class MyCifar10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCifar10, self).__init__()\n",
        "        self.m = nn.Sequential(\n",
        "                nn.Conv2d(3, 32, (5, 5), padding=2),\n",
        "                nn.MaxPool2d(2),\n",
        "                nn.Conv2d(32, 32, (5, 5), padding=2),\n",
        "                nn.MaxPool2d(2),\n",
        "                nn.Conv2d(32, 64, (5, 5), padding=2),\n",
        "                nn.MaxPool2d(2),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(1024, 64),\n",
        "                nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.m(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# tensorboard --logdir=logs\n",
        "writer = SummaryWriter(\"cifar10/{}/logs\".format(base_path))\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"device type: {}\".format(device))\n",
        "\n",
        "\n",
        "def begin_train():\n",
        "    # 准备 data\n",
        "    train_data = torchvision.datasets.CIFAR10(\"./cifar10\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "    test_data = torchvision.datasets.CIFAR10(\"./cifar10\", train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
        "    train_data_size = len(train_data)\n",
        "    test_data_size = len(test_data)\n",
        "    print(\"train_data_size:{}\".format(train_data_size))\n",
        "    print(\"test_data_size:{}\".format(test_data_size))\n",
        "    train_dataloader = DataLoader(dataset=train_data, batch_size=100, drop_last=False)\n",
        "    test_dataloader = DataLoader(dataset=test_data, batch_size=100, shuffle=True, num_workers=0, drop_last=False)\n",
        "\n",
        "    # 准备模型\n",
        "    myModel = MyCifar10()\n",
        "    myModel.to(device)\n",
        "\n",
        "    # loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    loss_fn = loss_fn.to(device)\n",
        "\n",
        "    # 优化器\n",
        "    learning_rate = 1e-2\n",
        "    # optimizer = torch.optim.SGD(myModel.parameters(), lr=learning_rate)\n",
        "    optimizer = torch.optim.SGD(myModel.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    total_train_step = 0\n",
        "    train_start_time = time.time()\n",
        "\n",
        "    for i in range(epoch):\n",
        "        epoch_start_time = time.time()\n",
        "        i += 1\n",
        "        print(\"-------------Epoch: {} ------------------\".format(i))\n",
        "        myModel.train()\n",
        "        for data in train_dataloader:\n",
        "            inputs, target = data\n",
        "            inputs = inputs.to(device)\n",
        "            target = target.to(device)\n",
        "            outputs = myModel(inputs)\n",
        "            loss = loss_fn(outputs, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_step += 1\n",
        "\n",
        "            if total_train_step % 100 == 0:\n",
        "                # print(\"train step: {}, time: {}, loss: {}\".format(total_train_step, (time.time() - epoch_start_time), loss.item()))\n",
        "                writer.add_scalar(tensorboard_name + \"_train_loss\", loss.item(), total_train_step)\n",
        "        print(\"train step: {}\".format(total_train_step))\n",
        "\n",
        "        # 开始测试\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0\n",
        "        myModel.eval()\n",
        "        with torch.no_grad():\n",
        "            for data in test_dataloader:\n",
        "                inputs, target = data\n",
        "                inputs = inputs.to(device)\n",
        "                target = target.to(device)\n",
        "                outputs = myModel(inputs)\n",
        "                loss = loss_fn(outputs, target)\n",
        "                total_loss += loss.item()\n",
        "                accuracy = (outputs.argmax(1) == target).sum()\n",
        "                total_accuracy += accuracy\n",
        "        print(\"test loss: {}\".format(total_loss))\n",
        "        print(\"test accuracy: {}\".format(total_accuracy / test_data_size))\n",
        "        writer.add_scalar(tensorboard_name + \"_test_loss\", total_loss, i)\n",
        "        writer.add_scalar(tensorboard_name + \"_test_acc\", total_accuracy / test_data_size, i)\n",
        "\n",
        "        # 保存模型\n",
        "        torch.save(myModel, \"cifar10/{}/model/m_ck_{}\".format(base_path, i))\n",
        "        torch.save(myModel.state_dict(), \"cifar10/{}/model/m_state_ck_{}\".format(base_path, i))\n",
        "        print(\"saved model {}, cost time: {}\".format(i, (time.time() - epoch_start_time)))\n",
        "\n",
        "    print(\"train cost time: {}\".format((time.time() - train_start_time)))\n",
        "\n",
        "\n",
        "def predict(image_path):\n",
        "    with torch.no_grad():\n",
        "        # myModel = torch.load(\"cifar10/m_ck_3\")\n",
        "        # myModel = torch.load(\"cifar10/model/m_ck_40\", map_location=torch.device('cpu'))\n",
        "\n",
        "        myModel = MyCifar10()\n",
        "        # myModel.load_state_dict(torch.load(\"cifar10/m_state_ck_40\"), strict=False)\n",
        "        myModel.load_state_dict(torch.load(\"cifar10/{}/model/m_state_ck_5\".format(base_path), map_location=torch.device('cpu')), strict=False)\n",
        "\n",
        "        myModel.to(device)\n",
        "        myModel.eval()\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        writer.add_images(tensorboard_name + \"_old\", torchvision.transforms.ToTensor()(image), 1, dataformats=\"CHW\")\n",
        "\n",
        "        transform = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize((32, 32)),\n",
        "            torchvision.transforms.ToTensor()\n",
        "        ])\n",
        "        image = transform(image)\n",
        "        writer.add_images(tensorboard_name + \"_new\", image, 1, dataformats=\"CHW\")\n",
        "        # print(image.shape)\n",
        "        output = myModel(torch.reshape(image, (1, 3, 32, 32)).to(device))\n",
        "        index = output.argmax(1).item()\n",
        "        # print(output)\n",
        "        for k in labels:\n",
        "            if labels[k] == index:\n",
        "                print(\"image: {}, index: {}, label: {}\".format(image_path, index, k))\n",
        "                break\n",
        "\n",
        "\n",
        "begin_train()\n",
        "print(labels)\n",
        "predict(image_path=\"./cifar10/imgs/dog.png\")\n",
        "predict(image_path=\"./cifar10/imgs/airplane.png\")\n",
        "predict(image_path=\"./cifar10/imgs/bird.png\")\n",
        "predict(image_path=\"./cifar10/imgs/deer.png\")\n",
        "predict(image_path=\"./cifar10/imgs/horse.png\")\n",
        "predict(image_path=\"./cifar10/imgs/truck.png\")\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device type: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train_data_size:50000\n",
            "test_data_size:10000\n",
            "-------------Epoch: 1 ------------------\n",
            "train step: 500\n",
            "test loss: 148.6210114955902\n",
            "test accuracy: 0.4592999815940857\n",
            "saved model 1, cost time: 13.08716082572937\n",
            "-------------Epoch: 2 ------------------\n",
            "train step: 1000\n",
            "test loss: 127.48356771469116\n",
            "test accuracy: 0.555899977684021\n",
            "saved model 2, cost time: 12.790632724761963\n",
            "-------------Epoch: 3 ------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7e9d6cd272ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m \u001b[0mbegin_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./cifar10/imgs/dog.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-7e9d6cd272ef>\u001b[0m in \u001b[0;36mbegin_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------Epoch: {} ------------------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I;16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     img = torch.from_numpy(\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}